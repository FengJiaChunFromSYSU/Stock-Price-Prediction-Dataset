<?xml version="1.0" encoding="UTF-8" standalone="no"?><Date date="2013-06-15"><Message type="ReplyMessage"><Id>1371279527925-1</Id><Topic><Title>CPU's Demoted to 2nd Class Citizens by GPUs in HPC</Title><Username>j7777kxx</Username><Timestamp>1278049385000</Timestamp><DateTime>Fri, 2010-07-02 01:43:05 EDT</DateTime></Topic><Msg>This guy is/was a swing trader and an occasional SA blogger who thought he knew it all. He also advocated energetically for JH's exit as CEO, and the divestiture of NV's Consumer business etc. "Splains" why he has disappeared from the market.</Msg><Username>ibexx</Username><Timestamp>1371279527925</Timestamp><DateTime>Sat, 2013-06-15 02:58:47 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371286957144-2</Id><Topic><Title>CPU's Demoted to 2nd Class Citizens by GPUs in HPC</Title><Username>j7777kxx</Username><Timestamp>1278049385000</Timestamp><DateTime>Fri, 2010-07-02 01:43:05 EDT</DateTime></Topic><Msg>'GPUs have dominated HPC for the past three years. ' No they haven't otherwise Teslas would be a billions of dollars business and it clearly isn't as HPC is 10% of the server market and clearly a Tesla is not being sold with each HPC server. GPUs are great for the odd application/benchmark like Linpack which is great for PR but most HPC is still done on cpus. ' The only way Intel could compete was with a updated version of the Larrabee GPU. And even there, Intel has needed to virtually give away the current Itanium-sized chip.' Larrabee was always more suited for HPC than gpu work, it's just Gelsinger did not realize it. They are also not being given away even in supercomputers as the processors usually are in a flagship supercomputer. Somebody calculated Intel was getting about $200 for each one in the TACC supercomputer and bought singly they will cost you over a K. They are also much better suited for HPC work than gpus from a software POV as they are basically highly vectorized updated and modernized Pentiums so all the existing x86 HPC software can run on them. The Chinese will reclaim the No.1 on the Top 500 list with a multi petaflop Xeon/Xeon Phi supercomputer when it is released next and unlike a Tesla one it will be able to run more software. Teslas will be forced into being even more niche than they already are.</Msg><Username>marsavian</Username><Timestamp>1371286957144</Timestamp><DateTime>Sat, 2013-06-15 05:02:37 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371287360013-3</Id><Topic><Title>Just got a 2nd GTX 680</Title><Username>ashraf.eassa</Username><Timestamp>1371267405218</Timestamp><DateTime>Fri, 2013-06-14 23:36:45 EDT</DateTime></Topic><Msg>You recognize the big difference between this generation of console and the previous generations. In the past, consoles provided graphic performance that couldn't be approached by any other consumer-level hardware. This generation will start out with the performance of a mid-range gaming PC, and slide down from there. The marketing people won't even be able to claim magic architecture pixie dust, because the hardware will be a x86 PC. This is great for Nvidia (and ATI) because gamers don't need to make a difficult decision. Many already have better rigs than the new consoles, and they can upgrade them without wondering if their investment will be bested by a console come Christmas. It should be interesting to watch how the market opinion evolves between now and the holiday wish list season. It's been a foregone conclusion that the core market would immediately upgrade to the next generation consoles. But without backwards compatibility, I think the success is still an open question.</Msg><Username>watergatefive</Username><Timestamp>1371287360013</Timestamp><DateTime>Sat, 2013-06-15 05:09:20 EDT</DateTime><ThumbUp>2</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371307048037-4</Id><Topic><Title>Just got a 2nd GTX 680</Title><Username>ashraf.eassa</Username><Timestamp>1371267405218</Timestamp><DateTime>Fri, 2013-06-14 23:36:45 EDT</DateTime></Topic><Msg>I think the cloud gaming concept of pay once play anywhere on any device has just been given a huge boost. M$FT has another Win 8 fiasco with the Xbox One.</Msg><Username>flstf_97</Username><Timestamp>1371307048037</Timestamp><DateTime>Sat, 2013-06-15 10:37:28 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371310991603-5</Id><Topic><Title>Just got a 2nd GTX 680</Title><Username>ashraf.eassa</Username><Timestamp>1371267405218</Timestamp><DateTime>Fri, 2013-06-14 23:36:45 EDT</DateTime></Topic><Msg>"You recognize the big difference between this generation of console and the previous generations. In the past, consoles provided graphic performance that couldn't be approached by any other consumer-level hardware." More often than not when we speak we show others our ignorance than what we know. Nvidia supplied the first Xbox with an average GPU and also supplied the PS3 with an average GPU. At the time Nvidia supplied GPUs for those consoles it was selling higher performing GPUs for PCs. Game Console graphics have never outperformed a well equiped PC, never. A $400 game console was not designed to take on a $1000 GPU card. The game console was designed to provide a well defined gaming platform for consumers and game developers at a resonable price. Today Nvidia is the supplier of the only PlayStation shipping, the PS3. Nvidia and ATI provided better performing GPU from the day the PS3 went on sale right up to today. And today Nvidia and AMD provide better performing GPUs than will be found in the Xbox One or PS4. It is often difficult to tell someone they said something ignorant but I find it is always better to say something than let that person remain ignorant and repeat an embarasing comment. If you do your homework you find that your statement was never true. Wikipedia list what GPUs that were in each game console when they were launched. IMHO</Msg><Username>xc3155</Username><Timestamp>1371310991603</Timestamp><DateTime>Sat, 2013-06-15 11:43:11 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="TopicMessage"><Id>1371313527251-6</Id><Title>Losing the Next Nexus 7 to Qualcomm means its time for Nvidia to rethink Tegra 4</Title><Msg>Losing the Next Nexus 7 to Qualcomm is worst than being shut out of all 3 game consoles. Nvidia will have to decide now if Tegra 4 and Tegra 4i are worth the effort with the winner for this round being Qualcomm. All the ARM SoC suppliers will reset in 2014 when 64 Bit ARM arrives. Nvidia would do well to concentrate on its 64 Bit ARM SoC efforts now and acknowledge that Tegra 4 and Tegra 4i will be too late to matter in the 32 Bit SoC battle. It would be sad to see Nvidia just as late to he 64 Bit battle trying to undo the Tegra 4 mistakes. Tegra 4 is DOA, Nvidia better hope its 64 Bit Tegra is on time and loaded for bear. imho</Msg><Username>xc3155</Username><Timestamp>1371313527251</Timestamp><DateTime>Sat, 2013-06-15 12:25:27 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371326270794-7</Id><Topic><Title>Xbox One Games At E3 Were Running On Windows 7 With Nvidia GTX Cards</Title><Username>nvdarocks</Username><Timestamp>1371247035571</Timestamp><DateTime>Fri, 2013-06-14 17:57:15 EDT</DateTime></Topic><Msg>"and that the talk of "performance optimization" for PC ports of AAA games for AMDs GPUs and CPUs will be negligible at best." It's complete BS spread by AMD fans, and anybody who understands how programming PC graphics works would agree.</Msg><Username>ashraf.eassa</Username><Timestamp>1371326270794</Timestamp><DateTime>Sat, 2013-06-15 15:57:50 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371327540277-8</Id><Topic><Title>Xbox One Games At E3 Were Running On Windows 7 With Nvidia GTX Cards</Title><Username>nvdarocks</Username><Timestamp>1371247035571</Timestamp><DateTime>Fri, 2013-06-14 17:57:15 EDT</DateTime></Topic><Msg>Also, does this mean that these machines were simulating unified memory with no performance issues?</Msg><Username>lrkbik4</Username><Timestamp>1371327540277</Timestamp><DateTime>Sat, 2013-06-15 16:19:00 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1371336783546-9</Id><Topic><Title>Xbox One Games At E3 Were Running On Windows 7 With Nvidia GTX Cards</Title><Username>nvdarocks</Username><Timestamp>1371247035571</Timestamp><DateTime>Fri, 2013-06-14 17:57:15 EDT</DateTime></Topic><Msg>Jason Evangelo of Forbes says it doesn't matter. I'm thinking of buying a Hyundai. So I went and test drove a 5 series BMW. Doesn't matter!</Msg><Username>nvdarocks</Username><Timestamp>1371336783546</Timestamp><DateTime>Sat, 2013-06-15 18:53:03 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment>Strong Buy</Sentiment></Message><Message type="ReplyMessage"><Id>1371346436560-10</Id><Topic><Title>Xbox One Games At E3 Were Running On Windows 7 With Nvidia GTX Cards</Title><Username>nvdarocks</Username><Timestamp>1371247035571</Timestamp><DateTime>Fri, 2013-06-14 17:57:15 EDT</DateTime></Topic><Msg>"The best experience is on an NVIDIA GPU" Wasn't that the mantra a few years ago? Guess it's still true. Obviously developer relations efforst matter a LOT.</Msg><Username>norcalnative_2</Username><Timestamp>1371346436560</Timestamp><DateTime>Sat, 2013-06-15 21:33:56 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message></Date>