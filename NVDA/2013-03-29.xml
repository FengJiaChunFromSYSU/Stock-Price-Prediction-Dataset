<?xml version="1.0" encoding="UTF-8" standalone="no"?><Date date="2013-03-29"><Message type="ReplyMessage"><Id>1364530777691-1</Id><Topic><Title>People holding out hope that Windows on ARM will exist after Windows Blue</Title><Username>will_amd_yu</Username><Timestamp>1364520617237</Timestamp><DateTime>Thu, 2013-03-28 21:30:17 EDT</DateTime></Topic><Msg>"Not exactly what I meant, do you believe the x86 architecture will be able to grow in the mobile field, long term, as much as ARM. Forget about Intel having this or that, the architectures themselves are what I am talking about." Haswell - 8 Watt TDP Tegra 4 - 5 Watt TDP Tegra 4i - 1 Watt TDP? Answer to your question Tablets - Yes - 2014 For sure significant market share = say 20% to 30% Phones - ??? 2014 to 2015 significant market share - say 15^ to 20% Key new Product Launch to watch.....Microsoft 7 inch tablet. If ARM version only then it will say one thing, If X86 version is also launched it will say something else. Puzzle - Why did Google launch an Android Chromebook with an X86 processor. Ridiculously expensive but don't you think there will be other X86 versions over time. The old dividing walls between Windows and X86 only and ARM and Android only are broken. When the power requirements and performance are in the same envelop although one might be slightly better than the other in something....Marketing, $$$$$, and EXECUTION will be the key. JMHO P.S. Nvidia using gaming chops as a marketing differentiator is brilliant</Msg><Username>j7777kxx</Username><Timestamp>1364530777691</Timestamp><DateTime>Fri, 2013-03-29 00:19:37 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>1</ThumbDown><Sentiment>Hold</Sentiment></Message><Message type="TopicMessage"><Id>1364536751815-2</Id><Title>ARM says GPGPUs could lower overall chip costs</Title><Msg>SAN FRANCISCO: CHIP DESIGNER ARM has said that chip vendors could cut down on costs by offloading processing to the GPU. ARM has been pushing its Mali GPU architecture both as a graphics engine and as a GPGPU accelerator through its support of OpenCL. The firm told The INQUIRER that not only could chip vendors see improved performance by offloading onto the GPU but they could also cut costs by moving tasks from dedicated silicon to the GPU. Ian Smythe, director of marketing at ARM told The INQUIRER that firms could move tasks such as image stabilisation over to the GPU, which is already on the system on chip (SoC), and cut back on other parts of the chip. Smythe said, "You might be able to save some cost somewhere in the SoC by cutting out a bit of hardware that you had and run it on the GPU instead. So cost reduction and an improved capability. So maybe they will cut out some of the ISP and they will do it on the GPU because the silicon is already there, it's power efficient, it's a quicker way of doing [it], you get a cost reduction, performance goes up." Aside from lower cost chips, Smythe's comments suggest that chip vendors and in particular vendors such as Samsung, which also develops software for its Android smartphones, will make use of GPGPUs as a way of cutting bill of materials costs and reducing chip complexity. Smythe added that GPGPU computing doesn't have a single 'killer application' but rather could be applied to use cases such as computational photography, as seen in the HTC One and gaming. However given Smythe's comments, perhaps the real killer application for hardware vendors will come from lower material costs.</Msg><Username>getanid61</Username><Timestamp>1364536751815</Timestamp><DateTime>Fri, 2013-03-29 01:59:11 EDT</DateTime><ThumbUp>4</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364581241415-3</Id><Topic><Title>Qualcomm admits it was wrong about the Samsung Galaxy S4 1080p@60fps</Title><Username>ibexx</Username><Timestamp>1364517902882</Timestamp><DateTime>Thu, 2013-03-28 20:45:02 EDT</DateTime></Topic><Msg>Every part of the pipeline has to be working well for a present day chip to do 1080p@60fps. That's a lot of memory bandwidth, it pushes the limit of the storage card. My guess is that encoder sections of the pipeline aren't keeping up. If you can't do good compression, the rest of the system will fall over. It's nothing to be concerned about. Being able to record at 1080p at all is impressive. Most TV content is 720p or 1080i (and mediocre quality at that) by the time it is viewed by the typical US viewer.</Msg><Username>watergatefive</Username><Timestamp>1364581241415</Timestamp><DateTime>Fri, 2013-03-29 14:20:41 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364581345810-4</Id><Topic><Title>ARM says GPGPUs could lower overall chip costs</Title><Username>getanid61</Username><Timestamp>1364536751815</Timestamp><DateTime>Fri, 2013-03-29 01:59:11 EDT</DateTime></Topic><Msg>Huge endorsement for Nvidia there. ARMH understands that GPGPUs can be both faster and more power effective at computing. They have big challenges to become competitive with Nvidia in that domain. The three main approaches are CUDA, OpenCL and OpenACC. CUDA was the source of GPGPU innovation, showing what was possible. It inspired OpenCL as a me-too system, positioned as an alternative not tied to Nvidia hardware. For a while OpenCL was comparable to CUDA, but CUDA has since evolved from a language extension into a broad programming system. The OpenCL implementations are far behind in quality and performance due to years of heavy investment in CUDA by Nvidia, while other vendors only lightly dabbled in OpenCL.</Msg><Username>watergatefive</Username><Timestamp>1364581345810</Timestamp><DateTime>Fri, 2013-03-29 14:22:25 EDT</DateTime><ThumbUp>5</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="TopicMessage"><Id>1364582990201-5</Id><Title>Apple sucks in the cloud....Microsoft and Google better</Title><Msg>SOURCE: Tech Pinions Part 1: Apple is really bad at the cloud. And while that is not hurting the company much today, it is going to become a growing problem as users rely on a growing number of devices and come to expect that all of their data will be available on all of their devices all of the time. Apple’s cloudy difficulties are becoming apparent through growing unhappiness among developers about the many flaws of Apple’s iCloud synchronization service. Ars Technica has a good survey of developer’s complaints about the challenges iCloud poses for developers. This long Tumblr post by Rich Siegel of Bare Bones Software is a deeper dive into some moderately technical detail. These developer issues matter to both Apple and to its customers because iCloud is not being integrated into third-party apps, and some that have integrated it are abandoning it. This leaves users with limited and often complicated solutions for access to their data. Like most tech writers, I’m an extreme case, working regularly on a large assortment of devices working in different ecosystems. I rely on a variety of tools to sync my data, an approach that can be a configuration nightmare. But even someone living entirely within the Mac-iOS ecosystem cannot count on iCloud to provide anything near a complete solution. Just try to move PDF document from a Mac to an iPad.</Msg><Username>ibexx</Username><Timestamp>1364582990201</Timestamp><DateTime>Fri, 2013-03-29 14:49:50 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364583100464-6</Id><Topic><Title>Apple sucks in the cloud....Microsoft and Google better</Title><Username>ibexx</Username><Timestamp>1364582990201</Timestamp><DateTime>Fri, 2013-03-29 14:49:50 EDT</DateTime></Topic><Msg>Part 2: The fact is that both Microsoft and Google are far ahead of Apple in cloud services. Microsoft has built on its years of experience with SharePoint and Exchange, plus such commercially unsuccessful but technically important projects as Groove and Live Mesh, to build SkyDrive and its associated services. Google has always lived in the cloud and has put its expertise behind Google Drive. Smaller vendors, such as DropBox and SugarSync, also offer solutions far superior to Apple’s. But all of these companies have taken years to get where they are in large part because this stuff is really, really hard. None of them offers a complete multiplatform, multidevice, multi-application solution, but they are getting there. Cloud information management solutions are only going to get more important as users choose among multiple devices to pick the one best suited to the need at hand. For many, these devices will be heterogeneous, perhaps an Android phone, and iPad tablet, and a Windows PC. The winners will be service providers who make a full range of services available to all devices on all platforms. Microsoft and Google come close, working hard to look beyond Windows and Android, respectively. Apple provides only grudging iCloud support to non-Apple devices, another self-imposed handicap. Apple has the advantage of starting in this new multidevice world with the best-integrated solutions. But it is serious danger of blowing that lead unless it can drastically improve its cloud offerings. And one more thing: The cloud imposes new security challenges for service providers. This is a problem no one has solved yet, but Apple has failed particularly miserably. Check out this Verge article for a good rundown on iCloud security failings.</Msg><Username>ibexx</Username><Timestamp>1364583100464</Timestamp><DateTime>Fri, 2013-03-29 14:51:40 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364583320422-7</Id><Topic><Title>ARM says GPGPUs could lower overall chip costs</Title><Username>getanid61</Username><Timestamp>1364536751815</Timestamp><DateTime>Fri, 2013-03-29 01:59:11 EDT</DateTime></Topic><Msg>And the latest iteration of that investment is Python: "Python is used in several different areas; though perhaps most widely known as an easy to learn, dynamically typed language common in scripting and prototyping, it’s also used professionally in fields such as engineering and “big data” analytics, the latter of which is where Continuum’s specific market comes in to play. For NVIDIA this brings with it both the benefit of making CUDA more accessible due to Python’s reputation for simplicity, and at the same time opening the door to new HPC industries." - from anandtech</Msg><Username>norcalnative_2</Username><Timestamp>1364583320422</Timestamp><DateTime>Fri, 2013-03-29 14:55:20 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364583468724-8</Id><Topic><Title>screwish boy indicted!</Title><Username>screwherbes</Username><Timestamp>1364567886529</Timestamp><DateTime>Fri, 2013-03-29 10:38:06 EDT</DateTime></Topic><Msg>Screws</Msg><Username>tomasco3777</Username><Timestamp>1364583468724</Timestamp><DateTime>Fri, 2013-03-29 14:57:48 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364585811703-9</Id><Topic><Title>screwish boy indicted!</Title><Username>screwherbes</Username><Timestamp>1364567886529</Timestamp><DateTime>Fri, 2013-03-29 10:38:06 EDT</DateTime></Topic><Msg>NVDA will be much better off with the SAC boys behind the bars.</Msg><Username>ibexx</Username><Timestamp>1364585811703</Timestamp><DateTime>Fri, 2013-03-29 15:36:51 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>1</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364591837079-10</Id><Topic><Title>Qualcomm admits it was wrong about the Samsung Galaxy S4 1080p@60fps</Title><Username>ibexx</Username><Timestamp>1364517902882</Timestamp><DateTime>Thu, 2013-03-28 20:45:02 EDT</DateTime></Topic><Msg>Capitulating on a claim! Just like the part about "Cleaning Nvidia's Clock"</Msg><Username>anvda20</Username><Timestamp>1364591837079</Timestamp><DateTime>Fri, 2013-03-29 17:17:17 EDT</DateTime><ThumbUp>2</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="TopicMessage"><Id>1364601531521-11</Id><Title>What will Nvidia's graphics marketshare be this Q. 15% or 14%</Title><Msg>It was 16% last Q, and Ivy bridge is just hitting its stride right now.</Msg><Username>will_amd_yu</Username><Timestamp>1364601531521</Timestamp><DateTime>Fri, 2013-03-29 19:58:51 EDT</DateTime><ThumbUp>2</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="TopicMessage"><Id>1364607149790-12</Id><Title>Tegra 4: The end-all be-all when it comes to games?</Title><Msg>Nvidia Tegra 4 Flexes Its Muscles As many of you are already aware by now, the Nvidia Tegra 4 has been unveiled during CES, roughly within the same time-frame as the Snapdragon 600 and 800 and the Exynos 5 octa-core CPUs. About a month has passed ever since and we’re starting to hear more and more about these particular processors, well, except for the 8-core beast which, according to certain rumors, might’ve stumbled across some issues on the production line. Anyhow, the Tegra 4 is today’s highlight, and after we saw some impressive benchmark scores a few days ago, we’re now able to take a sneak peek at some real gaming capabilities. Nvidia Tegra 4 – Graphics I bet that when you hear the name “Nvidia” your mind automatically goes to “graphics”, and for good reason. The company is well renowned for its GPUs and the same philosophy has been somewhat valid when talking about smartphones as well. In other words, Tegra processors are usually expected to handle graphics better than any other chip out there. In fact, Tegra 3-exclusive games have been created in the past, simply because the chip is able to perform certain tasks that other CPUs can’t. Well, at least in theory. In any case, if you’re wondering what the upcoming Tegra 4 can bring new to the table in the graphics department, the video below will give you the answer. In the clip you’ll get to see the difference in graphics, between running Zombie Driver on Tegra 4 and non-Tegra 4 devices. Needless to say, Nvidia’s chip is able to deliver some pretty astonishing graphical elements, such as dynamic shadows and lighting. Hit that play button below and see for yourself, and if you’re wondering when you’ll be able to buy a Tegra 4 device, the company has previously stated that the new CPU should end up powering certain gadgets starting with Q2. SOURCE: gforgamesDOTcom</Msg><Username>ibexx</Username><Timestamp>1364607149790</Timestamp><DateTime>Fri, 2013-03-29 21:32:29 EDT</DateTime><ThumbUp>4</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="TopicMessage"><Id>1364613776207-13</Id><Title>Faceboo - HTC - Nvidia</Title><Msg>You heard it hear first - Facebook/HTC phone is powered by Nvidia. Camera and HDR support will be exploited by Facebook/Instagram to create differentiation.</Msg><Username>o.investor</Username><Timestamp>1364613776207</Timestamp><DateTime>Fri, 2013-03-29 23:22:56 EDT</DateTime><ThumbUp>1</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message><Message type="ReplyMessage"><Id>1364614798636-14</Id><Topic><Title>Faceboo - HTC - Nvidia</Title><Username>o.investor</Username><Timestamp>1364613776207</Timestamp><DateTime>Fri, 2013-03-29 23:22:56 EDT</DateTime></Topic><Msg>More likely is a Facebook app store that will be announced. Actually a phone would be a long-shot.</Msg><Username>chitownbarber20</Username><Timestamp>1364614798636</Timestamp><DateTime>Fri, 2013-03-29 23:39:58 EDT</DateTime><ThumbUp>0</ThumbUp><ThumbDown>0</ThumbDown><Sentiment/></Message></Date>